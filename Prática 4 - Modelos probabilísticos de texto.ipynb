{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelando Textos Probabilisticamente\n",
    "====================================\n",
    "\n",
    "Nesta prática, vamos usar redes neurais para estimar as probabilidades condicionais de textos, caractere a caractere.\n",
    "Para uma discussão interessante sobre o assunto, veja o seguinte blog: http://karpathy.github.io/2015/05/21/rnn-effectiveness/.\n",
    "\n",
    "Vamos usar a biblioteca Keras adaptando um de seus exemplos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro vamos utilizar o mesmo texto usado no exemplo original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = get_file('nietzsche.txt', origin=\"https://s3.amazonaws.com/text-datasets/nietzsche.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try: \n",
    "    text = open(path).read().lower()\n",
    "except UnicodeDecodeError:\n",
    "    import codecs\n",
    "    text = codecs.open(path, encoding='utf-8').read().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comprimento do corpus: 600893\n"
     ]
    }
   ],
   "source": [
    "print('Comprimento do corpus:', len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como o  modelo vai se basear em caracteres, precisamos definir o conjunto de caracteres do texto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 57\n"
     ]
    }
   ],
   "source": [
    "chars = set(text)\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O modelo envolve probabilidades condicionais entre caracteres consecutivos, então precisamos alimentar o modelo com sequências de caracteres, com sobreposição."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num sequences: 200291\n"
     ]
    }
   ],
   "source": [
    "maxlen = 20\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('num sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vetorizando...\n"
     ]
    }
   ],
   "source": [
    "print('Vetorizando...')\n",
    "X = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Construindo o modelo...\n"
     ]
    }
   ],
   "source": [
    "print('Construindo o modelo...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(512, return_sequences=True, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(512, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(a, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    a = np.exp(np.log(a) / temperature)\n",
    "    a /= a.sum() +.001\n",
    "    try:\n",
    "        sp = np.argmax(st.multinomial.rvs(1,a,1))\n",
    "        \n",
    "#         sp = np.argmax(np.random.multinomial(1, a, 1))\n",
    "    except ValueError as e:\n",
    "        print(a[:-1].sum(), len(a),a)\n",
    "        raise(e)\n",
    "    return  sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "200291/200291 [==============================] - 87s - loss: 1.4636    \n",
      "Epoch 2/5\n",
      "200291/200291 [==============================] - 87s - loss: 1.3965    \n",
      "Epoch 3/5\n",
      "200291/200291 [==============================] - 87s - loss: 1.3391    \n",
      "Epoch 4/5\n",
      "200291/200291 [==============================] - 87s - loss: 1.2856    \n",
      "Epoch 5/5\n",
      "200291/200291 [==============================] - 87s - loss: 1.2323    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7faccc0c1fd0>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.fit(X, y, batch_size=1024, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \" distress, and twice\"\n",
      " distress, and twice the -nothere --who --the ---the ---the ---the --but as the ------                                                                                                                                                                                                                                                                                                                                              \n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" distress, and twice\"\n",
      " distress, and twice the same as a discreating the artists, -who are selicate instincts of the soul, who has such a grateful and expeciences, the ansters of a tho-soral will to all the problem of the free spirit of the eternal life in the contrariction of the individual with the same with the most depe-denion of the same for the artist in others had the sense of the contrary the whole shall then have been maxe for th\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \" distress, and twice\"\n",
      " distress, and twice made to table hoow to appear our vidtle assoribils in cause\n",
      "(for un-a sincal who, he does -as a othery man ampression of the truth of spiret and juigh. the one that the boxturing of a question thit manner\n",
      "as anything will be one's regises to all morality as a ned whole wroephysi?d, foreough the cleatem and timest.=--ohrist all the jewice as indifies, and\n",
      "\n",
      "bonourse--that not do we all grant spcill\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \" distress, and twice\"\n",
      " distress, and twice th-- nargless, in a down and down spirils, indience\n",
      "of compulison\n",
      "with the invacual instincts of very maik\n",
      "to goodhe like their purpore, bat stort\n",
      "remotnest,\n",
      "nirkly raceristic as air lodined by\n",
      "\"with the \"jud\n",
      "that is not too majodiows! for how kilselt of long ashelloging them becomes the\n",
      "world; the christian and is whole favoraous deserved in philosorr,\n",
      "philosophers, for a! remains or the \"dperem\n"
     ]
    }
   ],
   "source": [
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print()\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.multinomial.rvs(1,[0.5,0.5,0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
